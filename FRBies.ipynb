{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, define the user-specific constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "These parameters describe the FRB that you want results for. Example:\n",
    "\n",
    "FRB_Name = 'Spock'\n",
    "FRB_Ra = 323.477\n",
    "FRB_Dec = 13.244\n",
    "host_redshift = 0.367\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "Put your Casjobs user ID here. If you do not have one, you can make an account at: https://mastweb.stsci.edu/ps1casjobs/CreateAccount.aspx\n",
    "'''\n",
    "\n",
    "CASJOBS_WSID_string = '' #string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import dependencies and input the FRB information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from astropy.table import Row\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import download_file\n",
    "from photutils.aperture import aperture_photometry, CircularAperture, CircularAnnulus, ApertureStats\n",
    "from astropy.cosmology import WMAP9 as cosmo\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.use('TkAgg')\n",
    "from numpy import *\n",
    "from pylab import *\n",
    "from scipy import stats\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.wcs import WCS\n",
    "from astropy import coordinates, units\n",
    "from astropy.io import ascii\n",
    "import mastcasjobs\n",
    "from psquery import mastquery, sed\n",
    "import dustmaps.sfd\n",
    "import getpass\n",
    "import os\n",
    "os.environ[\"CASJOBS_WSID\"] = CASJOBS_WSID_string\n",
    "import re\n",
    "from psquery import get_coord\n",
    "import time, sys, os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy\n",
    "import fsps\n",
    "import sedpy\n",
    "import prospect\n",
    "import emcee\n",
    "import dynesty\n",
    "from matplotlib.pyplot import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# re-defining plotting defaults\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizestring = '2400'\n",
    "size = 2400\n",
    "radius = 15\n",
    "cone = 300/3600 #in degrees\n",
    "format = 'fits'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up our output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(FRB_Name+' Results.txt', 'w')\n",
    "file.write(FRB_Name+' coordinates: ('+str(FRB_Ra)+', '+str(FRB_Dec)+')\\n\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the file reading functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geturl(ra, dec, size, filter):\n",
    "\n",
    "    '''\n",
    "    Function that creates a PanStarrs FITS url to download.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ra  : float\n",
    "        J2000 RA of center of image in degrees\n",
    "\n",
    "    dec : float\n",
    "        J2000 Dec of center of image in degrees\n",
    "\n",
    "    size : integer\n",
    "        image size in pixels where 240 pixels is 60 arcsec\n",
    "\n",
    "    filter : string\n",
    "        desired filter for the image (g, r, i, z, or y)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    url : string\n",
    "        desired url to unpack for a FITS file\n",
    "    '''\n",
    "    \n",
    "    format, output_size, color = \"fits\", None, False\n",
    "\n",
    "    service = \"https://ps1images.stsci.edu/cgi-bin/ps1filenames.py\"\n",
    "    \n",
    "    url = (\"{service}?ra={ra}&dec={dec}&size={size}&format=fits\"\n",
    "           \"&filters={filter}\").format(**locals())\n",
    "    table = Table.read(url, format='ascii')\n",
    "    \n",
    "    url = (\"https://ps1images.stsci.edu/cgi-bin/fitscut.cgi?\"\n",
    "           \"ra={ra}&dec={dec}&size={size}&format={format}\").format(**locals())\n",
    "\n",
    "    urlbase = url + \"&red=\"\n",
    "    url = []\n",
    "    for filename in table['filename']:\n",
    "        url.append(urlbase+filename)\n",
    "        \n",
    "    return url\n",
    "\n",
    "def readfile(ra, dec, size, filter):\n",
    "      '''\n",
    "      This function runs the get_url() function, creates a path, and downloads the FITS file data and header. \n",
    "\n",
    "      Parameters:\n",
    "      -----------\n",
    "      ra  : float\n",
    "            J2000 RA of center of image in degrees\n",
    "\n",
    "      dec : float\n",
    "            J2000 Dec of center of image in degrees\n",
    "\n",
    "            size : integer\n",
    "            image size in pixels where 240 pixels is 60 arcsec\n",
    "\n",
    "      filter : string\n",
    "                  desired filter for the image (g, r, i, z, or y)\n",
    "\n",
    "      Returns:\n",
    "      -------\n",
    "      data : numpy.ndarray\n",
    "            data describing the FITS file\n",
    "\n",
    "      header: astropy.io.fits.header.Header\n",
    "              header for the FITS file containing information about the collection processes and image reduction\n",
    "      '''\n",
    "      if filter == 'h' or filter=='j':\n",
    "            path = filter+'_STACK_'+FRB_Name.upper()+'.fits'\n",
    "      else:\n",
    "            url=geturl(ra, dec, size, filter)[0]\n",
    "            path = download_file(url)\n",
    "\n",
    "      hdu = fits.open(path)\n",
    "      data = hdu[0].data\n",
    "      header = hdu[0].header\n",
    "      hdu.close()\n",
    "\n",
    "      return [data, header]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to run a query in the STRM database to pull surrounding galaxies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell uses the mastquery function from Casey Law's psquery package.\n",
    "\n",
    "Parameters:\n",
    "-----------\n",
    "\n",
    "FRB_Ra : float\n",
    "         RA defined above, in degrees\n",
    "\n",
    "FRB_Dec : float\n",
    "          Dec defined above, in degrees\n",
    "\n",
    "cone : float\n",
    "       radius of cone search defined above, in degrees\n",
    "\n",
    "selectcol : list\n",
    "            desired information from STRM, out of [\"objID\", \"raMean\", \"decMean\", \"z_phot0\", \"z_photErr\", \"prob_Galaxy\", \"prob_Star\", \"prob_QSO\"]\n",
    "\n",
    "Returns:\n",
    "--------\n",
    "\n",
    "STRM_results : astropy table\n",
    "               table of results from the mastquery search\n",
    "\n",
    "intervening_coords : list\n",
    "                     this is the list created in the STRM mastquery cell\n",
    "                     it has entries with the following form: \n",
    "                     [STRM_results[i]['raMean'], STRM_results[i]['decMean'], STRM_results[i]['z_phot0'], STRM_results[i]['z_photErr']]\n",
    "\n",
    "'''\n",
    "\n",
    "deg_in_rad = 57.2958\n",
    "virial_radius_mpc = 0.3\n",
    "\n",
    "STRM_results = mastquery.cone_ps1strm((FRB_Ra, FRB_Dec), cone, selectcol=[\"raMean\", \"decMean\", \"z_phot0\", \"z_photErr\", \"prob_Galaxy\", \"prob_Star\"])\n",
    "intervening_coords = []\n",
    "i = 0\n",
    "while i < len(STRM_results):\n",
    "    FRB_coord = SkyCoord(FRB_Ra*units.deg, FRB_Dec*units.deg, frame='icrs')\n",
    "    temp_coord = SkyCoord(STRM_results[i]['raMean']*units.deg, STRM_results[i]['decMean']*units.deg, frame='icrs')\n",
    "    separation = (FRB_coord.separation(temp_coord)).deg\n",
    "    d_mpc = (cosmo.angular_diameter_distance(z=(STRM_results[i]['z_phot0'])-2*STRM_results[i]['z_photErr'])).to_value()\n",
    "    theta_virial = 57.2958*(0.3/d_mpc)\n",
    "    #let's get rid of objects that probably aren't galaxies\n",
    "    if STRM_results[i]['prob_Galaxy'] < 0.5:\n",
    "        STRM_results.remove_row(i)\n",
    "    elif STRM_results[i]['prob_Star'] > 0.5:\n",
    "        STRM_results.remove_row(i)\n",
    "    #any object with a separation larger than the largest Virial radius is not at risk of intervening\n",
    "    elif separation > theta_virial:\n",
    "        STRM_results.remove_row(i)\n",
    "    #any object more distant than the FRB host is not at risk of intervening\n",
    "    #we use the smallest possible extreme of the zphot\n",
    "    elif STRM_results[i]['z_phot0'] - 2*STRM_results[i]['z_photErr'] > host_redshift:\n",
    "        STRM_results.remove_row(i)\n",
    "    #we assume that any object without a real zphot detection is not at risk of intervening\n",
    "    elif STRM_results[i]['z_phot0'] < 0:\n",
    "        STRM_results.remove_row(i)\n",
    "    else:\n",
    "        intervening_coords.append([STRM_results[i]['raMean'], STRM_results[i]['decMean'], STRM_results[i]['z_phot0'], STRM_results[i]['z_photErr'], separation])\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function runs the aperture photometry functions from photutils and calculates the error. \n",
    "\n",
    "The magnitude is found by the following equation:\n",
    "$$\n",
    "M = M_{ZPT} - 2.5\\log_{10}{\\frac{c \\cdot g}{t_{exp}}} \n",
    "$$\n",
    "...where $M_{ZPT}$ is the zero-point magnitude (25 for PanStarrs FITS files), $t_{exp}$ is the exposure time in seconds, $c$ is the counts per pixel, and $g$ is the photon-electron gain.\n",
    "\n",
    "The error in this magnitude can be approximated by:\n",
    "$$\n",
    "\\sigma_{M} \\approx \\frac{-2.5}{\\ln{10} \\cdot c} \\sqrt{\\left(A_{aperture} + \\frac{A_{aperture}^2}{A_{BG}}\\right)\\sigma_{BG}^2}\n",
    "$$\n",
    "\n",
    "And the 3-sigma upper limit on non-detections is then found with:\n",
    "\n",
    "$$\n",
    "M_{3\\sigma} = M_{ZPT} - 2.5\\log{\\left[\\mu_{BG}+3\\sigma_{BG}*\\frac{g}{t_{exp}}\\right]}\\pm{\\left|\\frac{2.5}{\\ln{10} \\cdot c}\\right|\\sqrt{\\sigma_{BG}^2\\left(A_{aperture}+\\frac{A_{aperture}^2}{A_{BG}}\\right)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmagnitude(data, header, radius, position, filter):\n",
    "\n",
    "    '''\n",
    "    Function that handles the aperture photometry and calculates associated error. \n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "           data describing the FITS file\n",
    "\n",
    "    header : astropy.io.fits.header.Header\n",
    "             header for the FITS file containing information about the collection processes and image reduction\n",
    "\n",
    "    radius : integer\n",
    "             radius of aperture in pixels\n",
    "\n",
    "    position : list \n",
    "               contains x and y coordinates (in pixels) of the center of the aperture\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    mag_and_error : list\n",
    "                    contains either the magnitude and error or the 3-sigma upper limit and the error\n",
    "                    if there is no detection, the error will be negative\n",
    "    \n",
    "    '''\n",
    "\n",
    "    Texp = header['EXPTIME']\n",
    "\n",
    "    if filter == 'h' or filter=='j':\n",
    "        ZPTmag = float(header['TMC_ZP'])\n",
    "        gain = float(header['GAIN'])\n",
    "    else:\n",
    "        ZPTmag = header['HIERARCH FPA.ZP']\n",
    "        gain = header['HIERARCH CELL.GAIN']\n",
    "\n",
    "    aperture = CircularAperture(position, radius)\n",
    "    annulus = CircularAnnulus(position, radius+2, np.sqrt(2*(radius**2+2*radius+2))) \n",
    "\n",
    "    phot_table = aperture_photometry(data, aperture)\n",
    "    ann_table = aperture_photometry(data, annulus)\n",
    "\n",
    "    counts = phot_table['aperture_sum'] - (ann_table['aperture_sum'])*(aperture.area/annulus.area)\n",
    "    \n",
    "    annstats  = ApertureStats(data, annulus)\n",
    "    annvar = (annstats.std)**2\n",
    "\n",
    "    count_error = np.sqrt(annvar*(aperture.area+(aperture.area**2)/annulus.area))\n",
    "    error = (2.5/(np.log(10)*counts))*count_error\n",
    "    upperlimcounts = annstats.mean+3*annstats.std\n",
    "    Ne = counts*gain\n",
    "    \n",
    "    if Ne/Texp > 0:\n",
    "        magnitude = ZPTmag - 2.5*np.log10(Ne/Texp)\n",
    "        mag_and_error = [magnitude[0], error[0]] \n",
    "    else:\n",
    "        Ne = ann_table['aperture_sum']*gain\n",
    "        magnitude = ('3Ïƒ: '+str(ZPTmag - 2.5*np.log10(upperlimcounts*gain/Texp)))\n",
    "        mag_and_error = [magnitude, str(\"{:.4f}\".format(error[0]))]\n",
    "\n",
    "    return mag_and_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getinfo(FRB_Name, FRBra, FRBdec, intervening_coords):\n",
    "\n",
    "    '''\n",
    "    Function that runs the get_magnitude function for a number of coordinates in the same field of view. \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    FRB_Name : string\n",
    "               name of FRB defined above\n",
    "\n",
    "    FRB_Ra : float\n",
    "         RA defined above, in degrees\n",
    "\n",
    "    FRB_Dec : float\n",
    "          Dec defined above, in degrees\n",
    "\n",
    "    intervening_coords : list\n",
    "                         this is the list created in the STRM mastquery cell\n",
    "                         it has entries with the following form: \n",
    "                         [STRM_results[i]['raMean'], STRM_results[i]['decMean'], STRM_results[i]['z_phot0'], STRM_results[i]['z_photErr']]\n",
    "\n",
    "    Returns: \n",
    "    --------\n",
    "\n",
    "    df : Pandas DataFrame\n",
    "         this contains all of the aperture photometry detections in each bandpass for each candidate\n",
    "    \n",
    "    '''\n",
    "    Name, Ra, Dec, Separation, zphot, zphot_err = [], [], [], [], [], []\n",
    "    filterdict = {'g':[], 'r':[], 'i':[], 'z':[], 'y':[], 'h':[], 'j':[]}\n",
    "    errordict = {'err_g':[], 'err_r':[], 'err_i':[], 'err_z':[], 'err_y':[], 'err_h':[], 'err_j':[]}\n",
    "    \n",
    "    j = 0\n",
    "    for coord in intervening_coords:\n",
    "        Name.append(FRB_Name+str(j))\n",
    "        ratemp = coord[0]\n",
    "        dectemp = coord[1]\n",
    "        zphot_temp = coord[2]\n",
    "        zphot_err_temp = coord[3]\n",
    "        separation_temp = coord[4]\n",
    "        Ra.append(ratemp)\n",
    "        Dec.append(dectemp)\n",
    "        zphot.append(zphot_temp)\n",
    "        zphot_err.append(zphot_err_temp)\n",
    "        Separation.append(separation_temp)\n",
    "        j+=1\n",
    "\n",
    "    for filter in filterdict:\n",
    "        file = readfile(FRBra, FRBdec, size, filter)\n",
    "        data = file[0]\n",
    "        header = file[1]\n",
    "        w = WCS(header)\n",
    "\n",
    "        for coord in intervening_coords:\n",
    "            ratemp = coord[0]\n",
    "            dectemp = coord[1]  \n",
    "            sky = SkyCoord(ra = ratemp, dec = dectemp, unit='deg')\n",
    "            position = w.world_to_pixel(sky)\n",
    "            mag_and_error = getmagnitude(data, header, radius, position, filter)\n",
    "            filterdict[filter].append(mag_and_error[0])\n",
    "            errordict['err_'+filter].append(mag_and_error[1])\n",
    "\n",
    "\n",
    "    content = {'Name': Name, 'RA': Ra, 'Dec': Dec, 'Separation': Separation, 'zphot': zphot, 'zphot_err': zphot_err,\n",
    "               'g': filterdict['g'], 'err_g' : errordict['err_g'],\n",
    "               'r': filterdict['r'], 'err_r' : errordict['err_r'],\n",
    "               'i': filterdict['i'], 'err_i' : errordict['err_i'],\n",
    "               'z': filterdict['z'], 'err_z' : errordict['err_z'],\n",
    "               'y': filterdict['y'], 'err_y' : errordict['err_y'],\n",
    "               'h': filterdict['h'], 'err_h' : errordict['err_h'],\n",
    "               'j': filterdict['j'], 'err_j' : errordict['err_j']}\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(content)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call a bunch of functions to perform aperture photometry on a wide range of candidates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervening_info = {'Name':[],\n",
    "                        'RA':[], \n",
    "                        'Dec':[], \n",
    "                        'Separation':[],\n",
    "                        'g':[],\n",
    "                        'err_g':[],\n",
    "                        'r':[],\n",
    "                        'err_r':[],\n",
    "                        'i':[],\n",
    "                        'err_i':[],\n",
    "                        'z':[],\n",
    "                        'err_z':[],\n",
    "                        'y':[],\n",
    "                        'err_y':[],\n",
    "                        'h':[],\n",
    "                        'err_h':[],\n",
    "                        'j':[],\n",
    "                        'err_j':[]}\n",
    "\n",
    "df = getinfo(FRB_Name, FRB_Ra, FRB_Dec, intervening_coords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to identify the detection that corresponds to the FRB host galaxy, and compare this to our known redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separations = df['Separation'].to_list()\n",
    "lowest_separation = min(separations)\n",
    "lowest_separation_index = np.argmin(separations)\n",
    "lowest_zphot = df.at[lowest_separation_index, 'zphot']\n",
    "lowest_zphot_err = df.at[lowest_separation_index, 'zphot_err']\n",
    "lowest_RA = df.at[lowest_separation_index, 'RA']\n",
    "lowest_Dec = df.at[lowest_separation_index, 'Dec']\n",
    "\n",
    "print('Photometric redshift: '+str(lowest_zphot))\n",
    "print('Photometric redshift error: '+str(lowest_zphot_err))\n",
    "print('Spectroscopic redshift: '+str(host_redshift))\n",
    "\n",
    "file = open(FRB_Name+' Results.txt', 'a')\n",
    "file.write('Below is the information for the source listed in STRM with the smallest separation from the localized FRB.\\n')\n",
    "file.write('It is possible that STRM will not have usable data for this detection, that the object is not real, or that it is not the host galaxy.\\n\\n')\n",
    "file.write('The closest detection was an object at ('+str(lowest_RA)+', '+str(lowest_Dec)+') with the following information:\\n')\n",
    "file.write('Photometric redshift: '+str(lowest_zphot))\n",
    "file.write('\\nPhotometric redshift: '+str(lowest_zphot_err))\n",
    "file.write('\\nCompare to the spectroscopic redshift: '+str(host_redshift))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get rid of the incomplete detections: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idlist = ['Name', 'RA', 'Dec', 'Separation', 'zphot', \n",
    "'zphot_err', 'g', 'err_g', 'r', 'err_r', 'i', 'err_i', \n",
    "'z', 'err_z', 'y', 'err_y', 'h', 'err_h', 'j', 'err_j']\n",
    "\n",
    "detection_names = []\n",
    "non_detection_names = []\n",
    "\n",
    "detections = pd.DataFrame(columns = idlist)\n",
    "non_detections = pd.DataFrame(columns = idlist)\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    for f in ['g', 'r', 'i', 'z', 'y', 'h', 'j']:\n",
    "        #we place aside objects that might intervene but are not detected in all bandpasses\n",
    "        if type(df.at[i,f]) == str:\n",
    "            non_detection_names.append(FRB_Name+str(i))\n",
    "            break\n",
    "        elif df.at[i,f] > 25.0:\n",
    "            non_detection_names.append(FRB_Name+str(i))\n",
    "            break\n",
    "        #we consider the rest to be viable, detected candidates\n",
    "        elif f == 'h':\n",
    "            detection_names.append(FRB_Name+str(i))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "for name in detection_names:\n",
    "    line = pd.DataFrame([df.iloc[int(name.lstrip(FRB_Name))].to_list()], columns = idlist)\n",
    "    detections = pd.concat([detections, line])\n",
    "\n",
    "for name in non_detection_names:\n",
    "    line = pd.DataFrame([df.iloc[int(name.lstrip(FRB_Name))].to_list()], columns = idlist)\n",
    "    non_detections = pd.concat([non_detections, line])\n",
    "\n",
    "detections = detections.set_index(pd.Index(range(0, len(detections))))\n",
    "non_detections = non_detections.set_index(pd.Index(range(0, len(non_detections))))\n",
    "\n",
    "print(len(detections))\n",
    "print(len(non_detections))\n",
    "print(detections)\n",
    "\n",
    "file = open(FRB_Name+' Results.txt', 'a')\n",
    "file.write('\\n\\nThe following sources were detected in all bandpasses and might intersect the FRB line of sight:\\n\\n')\n",
    "for id in idlist:\n",
    "    file.write(id+'   ')\n",
    "file.write('\\n')\n",
    "file.close()\n",
    "detections.to_csv(FRB_Name+' Results.txt', header=None, index=None, sep=' ', mode='a', float_format='%.4f')\n",
    "file = open(FRB_Name+' Results.txt', 'a')\n",
    "file.write('\\n\\nThe following sources were not detected in all bandpasses but might still intersect the FRB line of sight:\\n\\n')\n",
    "for id in idlist:\n",
    "    file.write(id+'   ')\n",
    "file.write('\\n')\n",
    "file.close()\n",
    "non_detections.to_csv(FRB_Name+' Results.txt', header=None, index=None, sep=' ', mode='a', float_format = '%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dustmaps.sfd\n",
    "dustmaps.sfd.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psquery\n",
    "for index in range(0, 1):\n",
    "\n",
    "    galaxy_name = detections.at[index, 'Name']\n",
    "    galaxy_separation = detections.at[index, 'Separation']\n",
    "    # galaxy_magnitudes = []\n",
    "    # galaxy_errors = []\n",
    "\n",
    "    # for filter in ['g', 'r', 'i', 'z', 'y']:\n",
    "    #     galaxy_magnitudes.append(detections.at[index, filter])\n",
    "    #     galaxy_errors.append(detections.at[index, 'err_'+filter])\n",
    "    # galaxy_redshift = detections.at[index, 'zphot']\n",
    "\n",
    "    phot = {'ps_g': detections.at[index, 'g'],\n",
    "    'ps_r': detections.at[index, 'r'],\n",
    "    'ps_i': detections.at[index, 'i'],\n",
    "    'ps_z': detections.at[index, 'z'],\n",
    "    'ps_y': detections.at[index, 'y'],\n",
    "    'twomass_H': detections.at[index, 'h'],\n",
    "    'ps_g_err': detections.at[index, 'err_g'],\n",
    "    'ps_r_err': detections.at[index, 'err_r'],\n",
    "    'ps_i_err': detections.at[index, 'err_i'],\n",
    "    'ps_z_err': detections.at[index, 'err_z'],\n",
    "    'ps_y_err': detections.at[index, 'err_y'],\n",
    "    'twomass_H_err': detections.at[index, 'err_h'],\n",
    "    'free_redshift': False,\n",
    "    'z': detections.at[index, 'zphot']}\n",
    "\n",
    "    coords = (SkyCoord(ra=detections.at[index, 'RA']*units.degree, dec=detections.at[index, 'Dec']*units.degree, frame='icrs')).to_string('hmsdms')\n",
    "    phot_extinct = sed.extinct(coords, phot)\n",
    "    output = psquery.sed.run_fit(phot_extinct)\n",
    "\n",
    "    file = open(FRB_Name+' Results.txt', 'a')\n",
    "    file.write('\\n'+galaxy_name+'\\n')\n",
    "    file.write('\\nSeparation: '+str(galaxy_separation)+'\\n')\n",
    "    file.write('\\nMass: ')\n",
    "    file.write(str(output[2][0]))\n",
    "    file.write('\\nlogzsol: ')\n",
    "    file.write(str(output[2][1]))\n",
    "    file.write('\\ndust2: ')\n",
    "    file.write(str(output[2][2]))\n",
    "    file.write('\\ntage: ')\n",
    "    file.write(str(output[2][3]))\n",
    "    file.write('\\ntau: ')\n",
    "    file.write(str(output[2][4]))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_obs(\n",
    "    phot,\n",
    "    filternames,\n",
    "    mag_err_clip=0.05,\n",
    "    **extras\n",
    "):\n",
    "    \"\"\"Build a dictionary of observational data.\n",
    "\n",
    "    phot = table or dictionary with photometry. Should already be extinction corrected.\n",
    "    Upper limits have flux=0 and \"err\" equal to the limit (in what units?).\n",
    "    filternames is list of bands and must match name in sedpy.\n",
    "    If None, names selected from the set available in sedpy.\n",
    "\n",
    "    returns obs: A dictionary of observational data to use in the fit.\n",
    "    \"\"\"\n",
    "\n",
    "    obs = {}\n",
    "    if filternames is None:\n",
    "        available = py.observate.list_available_filters()\n",
    "        sel = lambda x: any([(st in x.lower()) for st in available if \"err\" not in x])\n",
    "        filternames = list(filter(sel, phot.keys()))\n",
    "    flt_use = np.array([], dtype=\"S20\")\n",
    "    data_use, edata_use = np.array([]), np.array([])\n",
    "    for k in filternames:\n",
    "        if phot[k] != 0:\n",
    "            flt_use = np.append(flt_use, k)\n",
    "            data_use = np.append(data_use, phot[k])\n",
    "            edata_use = np.append(edata_use, phot[k + \"_err\"])\n",
    "\n",
    "    edata_use = np.array(edata_use)\n",
    "    edata_use = np.clip(edata_use, mag_err_clip, 10)\n",
    "    obs[\"islim\"] = edata_use <= 0\n",
    "\n",
    "    obs[\"filternames\"] = filternames\n",
    "    obs[\"filters\"] = sedpy.observate.load_filters(filternames)\n",
    "    obs[\"mags\"] = data_use\n",
    "    obs[\"mags_unc\"] = edata_use\n",
    "    obs[\"maggies\"] = 10 ** (-0.4 * obs[\"mags\"])  # fluxes in units of maggies (Jy/3631)\n",
    "    obs[\"maggies_unc\"] = np.log(10) / 2.5 * obs[\"mags_unc\"] * obs[\"maggies\"]\n",
    "\n",
    "    # deal with upper limits\n",
    "    # assume upper limits are 5-sigma (true for GALEX)\n",
    "    nsigma = np.repeat(5, len(obs[\"filternames\"]))\n",
    "    iswise = [i for i, w in enumerate(filternames) if \"wise\" in w]\n",
    "    nsigma[iswise] = 2  # WISE limits are 95%CL\n",
    "\n",
    "    obs[\"maggies_unc\"][obs[\"islim\"]] = (\n",
    "        10 ** (-0.4 * obs[\"mags\"][obs[\"islim\"]]) / nsigma[obs[\"islim\"]]\n",
    "    )\n",
    "    obs[\"maggies\"][obs[\"islim\"]] = 0\n",
    "\n",
    "    # Photometry mask, True = include in fit\n",
    "    obs[\"phot_mask\"] = np.array([True for f in obs[\"filters\"]])\n",
    "\n",
    "    # This is an array of effective wavelengths for each of the filters.\n",
    "    # It is not necessary, but it can be useful for plotting so we store it here as a convenience\n",
    "    obs[\"phot_wave\"] = np.array([f.wave_effective for f in obs[\"filters\"]])\n",
    "\n",
    "    # We do not have a spectrum, so we set some required elements of the obs dictionary to None.\n",
    "    obs[\"wavelength\"] = None\n",
    "    obs[\"spectrum\"] = None\n",
    "    obs[\"unc\"] = None\n",
    "    obs[\"mask\"] = None\n",
    "\n",
    "    # This function ensures all required keys are present in the obs dictionary,\n",
    "    # adding default values if necessary\n",
    "    obs = fix_obs(obs)\n",
    "\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(phot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "try:\n",
    "    import sedpy\n",
    "    from prospect.fitting import fit_model, lnprobfn\n",
    "    from prospect.likelihood import lnlike_phot, lnlike_spec, write_log\n",
    "    from prospect.models import priors, sedmodel\n",
    "    from prospect.models.templates import TemplateLibrary\n",
    "    from prospect.sources import CSPSpecBasis\n",
    "    from prospect.utils.obsutils import fix_obs\n",
    "    from prospect.plotting import sfh\n",
    "except ImportError:\n",
    "    print(\"sedpy or prospect not importing. cannot use sed modeling...\")\n",
    "# new imports\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import cosmology\n",
    "from astroquery.mast import Catalogs\n",
    "from dustmaps.sfd import SFDQuery\n",
    "from extinction import fitzpatrick99\n",
    "\n",
    "from psquery import irsaquery, psquery, noaoquery\n",
    "\n",
    "cosmo = cosmology.Planck18\n",
    "\n",
    "phot = {'ps_g': detections.at[index, 'g'],\n",
    "    'ps_r': detections.at[index, 'r'],\n",
    "    'ps_i': detections.at[index, 'i'],\n",
    "    'ps_z': detections.at[index, 'z'],\n",
    "    'ps_y': detections.at[index, 'y'],\n",
    "    'twomass_H': detections.at[index, 'h'],\n",
    "    'ps_g_err': detections.at[index, 'err_g'],\n",
    "    'ps_r_err': detections.at[index, 'err_r'],\n",
    "    'ps_i_err': detections.at[index, 'err_i'],\n",
    "    'ps_z_err': detections.at[index, 'err_z'],\n",
    "    'ps_y_err': detections.at[index, 'err_y'],\n",
    "    'twomass_H_err': detections.at[index, 'err_h'],\n",
    "\n",
    "    'free_redshift': False,\n",
    "    'z': detections.at[index, 'zphot']}\n",
    "\n",
    "coords = (SkyCoord(ra=detections.at[index, 'RA']*units.degree, dec=detections.at[index, 'Dec']*units.degree, frame='icrs')).to_string('hmsdms')\n",
    "phot_extinct = sed.extinct(coords, phot)\n",
    "\n",
    "def build_obs(\n",
    "    phot=None,\n",
    "    filternames=None,\n",
    "    mag_err_clip=0.05,\n",
    "    standard=[\"galex\", \"ps\", \"sdss\", \"wise\", \"decam\", \"twomass\"],\n",
    "    **extras\n",
    "):\n",
    "    \"\"\"Build a dictionary of observational data.\n",
    "    phot = table or dictionary with photometry. Should already be extinction corrected.\n",
    "    Upper limits have flux=0 and \"err\" equal to the limit (in what units?).\n",
    "    filternames is list of bands and must match name in sedpy.\n",
    "    If None, names inferred from phot using standard root names.\n",
    "    returns obs: A dictionary of observational data to use in the fit.\n",
    "    \"\"\"\n",
    "\n",
    "    obs = {}\n",
    "    if filternames is None:\n",
    "        sel = lambda x: any([(st in x.lower()) for st in standard if \"err\" not in x])\n",
    "        filternames = list(filter(sel, phot.keys()))\n",
    "    flt_use = np.array([], dtype=\"S20\")\n",
    "    data_use, edata_use = np.array([]), np.array([])\n",
    "    for k in filternames:\n",
    "        if phot[k] != 0:\n",
    "            flt_use = np.append(flt_use, k)\n",
    "            data_use = np.append(data_use, phot[k])\n",
    "            edata_use = np.append(edata_use, phot[k + \"_err\"])\n",
    "\n",
    "    edata_use = np.array(edata_use)\n",
    "    edata_use = np.clip(edata_use, mag_err_clip, 10)\n",
    "    obs[\"islim\"] = edata_use <= 0\n",
    "\n",
    "    obs[\"filternames\"] = filternames\n",
    "    obs[\"filters\"] = sedpy.observate.load_filters(filternames)\n",
    "    obs[\"mags\"] = data_use\n",
    "    obs[\"mags_unc\"] = edata_use\n",
    "    obs[\"maggies\"] = 10 ** (-0.4 * obs[\"mags\"])  # fluxes in units of maggies (Jy/3631)\n",
    "    obs[\"maggies_unc\"] = np.log(10) / 2.5 * obs[\"mags_unc\"] * obs[\"maggies\"]\n",
    "\n",
    "    # deal with upper limits\n",
    "    # assume upper limits are 5-sigma (true for GALEX)\n",
    "    nsigma = np.repeat(5, len(obs[\"filternames\"]))\n",
    "    iswise = [i for i, w in enumerate(filternames) if \"wise\" in w]\n",
    "    nsigma[iswise] = 2  # WISE limits are 95%CL\n",
    "\n",
    "    obs[\"maggies_unc\"][obs[\"islim\"]] = (\n",
    "        10 ** (-0.4 * obs[\"mags\"][obs[\"islim\"]]) / nsigma[obs[\"islim\"]]\n",
    "    )\n",
    "    obs[\"maggies\"][obs[\"islim\"]] = 0\n",
    "\n",
    "    # Photometry mask, True = include in fit\n",
    "    obs[\"phot_mask\"] = np.array([True for f in obs[\"filters\"]])\n",
    "\n",
    "    # This is an array of effective wavelengths for each of the filters.\n",
    "    # It is not necessary, but it can be useful for plotting so we store it here as a convenience\n",
    "    obs[\"phot_wave\"] = np.array([f.wave_effective for f in obs[\"filters\"]])\n",
    "\n",
    "    # We do not have a spectrum, so we set some required elements of the obs dictionary to None.\n",
    "    obs[\"wavelength\"] = None\n",
    "    obs[\"spectrum\"] = None\n",
    "    obs[\"unc\"] = None\n",
    "    obs[\"mask\"] = None\n",
    "\n",
    "    # This function ensures all required keys are present in the obs dictionary,\n",
    "    # adding default values if necessary\n",
    "    obs = fix_obs(obs)\n",
    "\n",
    "    return obs\n",
    "  \n",
    "obs = build_obs(phot = phot_extinct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
